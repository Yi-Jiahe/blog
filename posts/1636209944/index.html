<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=HandheldFriendly content="True"><meta http-equiv=X-UA-Compatible content="IE=edge"><meta http-equiv=Cache-Control content="no-transform"><meta http-equiv=Cache-Control content="no-siteapp"><meta name=generator content="Hugo 0.145.0"><link rel="shortcut icon" href=https://cdn.jsdelivr.net/gh/dsrkafuu/dsr-cdn-main@1/images/favicons/dsrca.ico><title>Sound Site Conception - Jiahe's Blog</title>
<meta name=keywords content="Audio,Web App"><meta property="og:title" content="Sound Site Conception"><meta name=twitter:title content="Sound Site Conception"><meta property="og:type" content="article"><meta property="og:url" content="https://blog.jiahe.dev/posts/1636209944/"><meta property="og:description" content="Sound site, (read: sound sight), is a small project I worked on a bit in late June, exploring the Web Audio API. The idea was to make a easily accessible way for people to visualize sound and explore the effects of audio effects on the waveform.
The basic idea of the Web Audio API is an Audio Routing Graph, which lives within an Audio Context. The graph is formed of individual Audio Nodes, of which there are three types, Sources or Inputs, Effects and Destinations or Outputs. Sources can be Oscillators which basically produce notes, Audio Recordings like files and Microphones. The Ouputs are basically the device speakers. Effects nodes can be compared to guitar effects pedals such as the DelayNode, DynamicsCompressorNode and GainNode. They do however, also provide functions like data analysis with the AnalyserNodes and other functions such as merging and splitting channels with the ChannelSplitterNode, ChannelMergerNode and audio spatialization."><meta name=twitter:description content="Sound site, (read: sound sight), is a small project I worked on a bit in late June, exploring the Web Audio API. The idea was to make a easily accessible way for people to visualize sound and explore the effects of audio effects on the waveform.
The basic idea of the Web Audio API is an Audio Routing Graph, which lives within an Audio Context. The graph is formed of individual Audio Nodes, of which there are three types, Sources or Inputs, Effects and Destinations or Outputs. Sources can be Oscillators which basically produce notes, Audio Recordings like files and Microphones. The Ouputs are basically the device speakers. Effects nodes can be compared to guitar effects pedals such as the DelayNode, DynamicsCompressorNode and GainNode. They do however, also provide functions like data analysis with the AnalyserNodes and other functions such as merging and splitting channels with the ChannelSplitterNode, ChannelMergerNode and audio spatialization."><meta name=twitter:card content="summary"><meta property="article:published_time" content="2021-11-06T22:45:44+08:00"><meta property="article:modified_time" content="2021-11-06T22:45:44+08:00"><style>@media(prefers-color-scheme:dark){body[data-theme=auto] img{filter:brightness(60%)}}body[data-theme=dark] img{filter:brightness(60%)}</style><link rel=stylesheet href=https://blog.jiahe.dev/assets/css/fuji.min.b4a21b5d3eb1d0a51297e31230a65fc25e387843e45ec3a2d9176cd8d163c216d99b9b13a618b28f537c3b559ec8a408183b0fbfad48daddb9befa7d3ef90eed.css integrity="sha512-tKIbXT6x0KUSl+MSMKZfwl44eEPkXsOi2Rds2NFjwhbZm5sTphiyj1N8O1WeyKQIGDsPv61I2t25vvp9PvkO7Q=="></head><body data-theme=auto data-theme-auto=false><script data-cfasync=false>var fujiThemeData=localStorage.getItem("fuji_data-theme");fujiThemeData?fujiThemeData!=="auto"&&document.body.setAttribute("data-theme",fujiThemeData==="dark"?"dark":"light"):localStorage.setItem("fuji_data-theme","auto")</script><header></header><main><div class="container-lg clearfix"><div class="col-12 col-md-9 float-left content"><article><h1 class="post-item post-title"><a href=https://blog.jiahe.dev/posts/1636209944/>Sound Site Conception</a></h1><div class="post-item post-meta"><span><i class="iconfont icon-today-sharp"></i>&nbsp;2021-11-06</span>
<span><i class="iconfont icon-pricetags-sharp"></i>&nbsp;<a href=/tags/audio>Audio</a>&nbsp;<a href=/tags/web-app>Web App</a>&nbsp;</span></div><div class="post-content markdown-body"><p><a href=https://github.com/Yi-Jiahe/soundsite target=_blank>Sound site</a>, (read: sound sight), is a small project I worked on a bit in late June, exploring the <a href=https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API target=_blank>Web Audio API</a>. The idea was to make a easily accessible way for people to visualize sound and explore the effects of audio effects on the waveform.</p><p>The basic idea of the Web Audio API is an Audio Routing Graph, which lives within an Audio Context. The graph is formed of individual Audio Nodes, of which there are three types, Sources or Inputs, Effects and Destinations or Outputs. Sources can be Oscillators which basically produce notes, Audio Recordings like files and Microphones. The Ouputs are basically the device speakers. Effects nodes can be compared to guitar effects pedals such as the DelayNode, DynamicsCompressorNode and GainNode. They do however, also provide functions like data analysis with the AnalyserNodes and other functions such as merging and splitting channels with the ChannelSplitterNode, ChannelMergerNode and audio spatialization.</p><p>Sound site makes use of the Web Audio API to build an Audio Graph starting from the device microphone, and ending with the device speakers. After the source node and before the destination are AnalyserNodes, which provide the FFT and waveform of the input and output waves to visualize the effects of the effects on the waveform.</p><p>While I have put the project on hold due to limited interactivity making it difficult for users to influence the audio graph, the next goal when I return to the project will be to work on the front end to allow users to touch their sound on top of seeing it.</p></div></article></div><aside class="col-12 col-md-3 float-left sidebar"><div class="sidebar-item sidebar-pages"><h3>Pages</h3><ul></ul></div><div class="sidebar-item sidebar-toc"><h3>Table of Contents</h3><nav id=TableOfContents></nav></div></aside></div><div class=btn><div class=btn-menu id=btn-menu><i class="iconfont icon-grid-sharp"></i></div><div class=btn-toggle-mode><i class="iconfont icon-contrast-sharp"></i></div><div class=btn-scroll-top><i class="iconfont icon-chevron-up-circle-sharp"></i></div></div><aside class=sidebar-mobile style=display:none><div class=sidebar-wrapper><div class="sidebar-item sidebar-pages"><h3>Pages</h3><ul></ul></div><div class="sidebar-item sidebar-links"><h3>Links</h3><ul></ul></div><div class="sidebar-item sidebar-tags"><h3>Tags</h3><div><span><a href=/tags/audio/>Audio</a>
</span><span><a href=/tags/cloud/>Cloud</a>
</span><span><a href=/tags/devlog/>Devlog</a>
</span><span><a href=/tags/drone/>Drone</a>
</span><span><a href=/tags/eink/>EInk</a>
</span><span><a href=/tags/embedded/>Embedded</a>
</span><span><a href=/tags/java/>Java</a>
</span><span><a href=/tags/meta/>Meta</a>
</span><span><a href=/tags/order-book/>Order Book</a>
</span><span><a href=/tags/tentatwo/>TentaTwo</a>
</span><span><a href=/tags/web/>Web</a>
</span><span><a href=/tags/web-app/>Web App</a></span></div></div></div></aside></main><footer><div class="container-lg clearfix"><div class="col-12 footer"><span>&copy; 2025
<a href=https://blog.jiahe.dev/></a>| Powered by <a href=https://github.com/andrew-aiken/hugo-theme-fuji/ target=_blank>Fuji</a> & <a href=https://gohugo.io/ target=_blank>Hugo</a></span></div></div></footer><script defer src=https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js integrity="sha512-N9IJRoc3LaP3NDoiGkcPa4gG94kapGpaA5Zq9/Dr04uf5TbLFU5q0o8AbRhLKUUlp8QFS2u7S+Yti0U7QtuZvQ==" crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/lazysizes@5.3.2/lazysizes.min.js integrity="sha512-q583ppKrCRc7N5O0n2nzUiJ+suUv7Et1JGels4bXOaMFQcamPk9HjdUknZuuFjBNs7tsMuadge5k9RzdmO+1GQ==" crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/prismjs@1.27.0/components/prism-core.min.js integrity="sha512-LCKPTo0gtJ74zCNMbWw04ltmujpzSR4oW+fgN+Y1YclhM5ZrHCZQAJE4quEodcI/G122sRhSGU2BsSRUZ2Gu3w==" crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/prismjs@1.27.0/plugins/autoloader/prism-autoloader.min.js integrity="sha512-GP4x8UWxWyh4BMbyJGOGneiTbkrWEF5izsVJByzVLodP8CuJH/n936+yQDMJJrOPUHLgyPbLiGw2rXmdvGdXHA==" crossorigin=anonymous></script><script defer src=/assets/js/fuji.min.645f1123be695831f419ab54c1bcba327325895c740014006e57070d4f3e5d6b553e929c4b46f40ea707249e9c7f7c2a446d32a39ce7319f80a34525586a8e0f.js integrity="sha512-ZF8RI75pWDH0GatUwby6MnMliVx0ABQAblcHDU8+XWtVPpKcS0b0DqcHJJ6cf3wqRG0yo5znMZ+Ao0UlWGqODw=="></script></body></html>